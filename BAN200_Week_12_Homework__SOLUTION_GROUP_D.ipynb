{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WstUJNksE6Y0"
      },
      "source": [
        "# BAN200 Week 12 Homework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltACN10fE91-"
      },
      "source": [
        "To complete the homework you will need to modify this template by adding Python code and/or text.\n",
        "\n",
        "Before starting the homework, make sure to save a copy of this template to your personal Google Drive. If you haven't saved your own copy, any changes you make will be lost when you close your browser window.\n",
        "\n",
        "To submit your homework: go to \"File\" in the Colab menu bar > select \"Download\" > select \"Download .ipynb\". This will download a \".ipynb\" file to your computer. You must submit this file.\n",
        "\n",
        "The homework is to be completed in groups. It is due at the start of next class.\n",
        "\n",
        "Homework is graded on the following scale:\n",
        "\n",
        "* *100%* -- The assignment was submitted on time, any code runs without errors, and every question is answered correctly.\n",
        "\n",
        "* *80%* -- The assignment was submitted on time, any code runs without errors, and every question is answered. Some questions may be incorrect, but the submission demonstrates an average level of effort and average level of understanding of the material.\n",
        "\n",
        "* *60%* -- The submission demonstrates a below-average level of effort and below-average level of understanding of the material. This is the highest grade that should be given to submissions that are submitted late, have code that throws uncaught errors, or leave some questions unanswered.\n",
        "\n",
        "* *0%* -- No assignment was submitted, or the submission demonstrates little-to-no effort and little-to-no understanding of the material."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3VCPhhjBSKQ"
      },
      "source": [
        "# Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Eb--NqDBSZD"
      },
      "source": [
        "Create a fine-tuned model using OpenAI's API. Use a different dataset than the one we used in class -- you can create your own or find one online. If you'd like to avoid API charges, keep the dataset small (10 to 20 records). Make sure to test your fine-tuned model after it is built."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmTiz-pxnjeG",
        "outputId": "44327ed1-74e0-4cb2-b57a-062457e5828e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.8-py3-none-any.whl (221 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.5/221.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.8\n",
            "Name: openai\n",
            "Version: 1.3.8\n",
            "Summary: The official Python library for the openai API\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: OpenAI <support@openai.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n",
            "Required-by: llmx\n"
          ]
        }
      ],
      "source": [
        "# put your answer here\n",
        "\n",
        "# install necessary packages\n",
        "!pip install openai\n",
        "!pip show openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "st4IV66xnjeI",
        "outputId": "651dd2f9-14c8-421b-8b50-30c7b016ce4d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bbffba9d06f4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# set up api_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'api_key.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'api_key.txt'"
          ]
        }
      ],
      "source": [
        "# set up api_key\n",
        "with open('api_key.txt') as f:\n",
        "    api_key = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QebGp8SN1x3v",
        "outputId": "0ed324ec-13b3-4c25-ab2d-8fdc955e4117"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning job created: ftjob-xOeoHqwcg9EaMWkYyYQlOGME\n"
          ]
        }
      ],
      "source": [
        "# put your answer here\n",
        "\n",
        "# Set up OpenAI API\n",
        "import time\n",
        "import openai\n",
        "openai.api_key = api_key\n",
        "\n",
        "fine_tuning_job =openai.FineTuningJob.create(\n",
        "    training_file=\"file-eqXEkYejQWB7E36rDdRbrkU6\",\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")\n",
        "\n",
        "# Monitor the fine-tuning process\n",
        "print(f\"Fine-tuning job created: {fine_tuning_job['id']}\")\n",
        "\n",
        "while True:\n",
        "\n",
        "    if fine_tuning_job[\"status\"] == \"succeeded\":\n",
        "        print(\"Fine-tuning completed successfully!\")\n",
        "        break\n",
        "    elif fine_tuning_job[\"status\"] == \"failed\":\n",
        "        print(\"Fine-tuning failed.\")\n",
        "        break\n",
        "\n",
        "# Access the fine-tuned model\n",
        "fine_tuned_model_id = fine_tuning_job[\"fine_tuned_model\"]\n",
        "print(f\"Fine-tuned model ID: {fine_tuned_model_id}\")\n",
        "\n",
        "completion = openai.chat.completions.create(\n",
        "  model=\"ft:gpt-3.5-turbo:my-org:custom_suffix:id\",\n",
        "  messages=[{\"role\": \"system\", \"content\": \"You are a magic 8 ball that answers in idioms.\"},\n",
        "            {\"role\": \"user\", \"content\": \"Will my favorite sports team win the championship this year?\"}\n",
        "      ]\n",
        "  )\n",
        "print(completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssBxtS1knjeJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}